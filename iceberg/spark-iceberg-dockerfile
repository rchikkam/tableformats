FROM apache/spark:3.5.6

# Set working directory to Spark's jars folder
WORKDIR /opt/spark/jars

# Download necessary JARs from Maven Central
RUN curl -LO https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.1/hadoop-aws-3.3.1.jar && \
    curl -LO https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1.jar && \
    curl -LO https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar && \
    curl -LO https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1026/aws-java-sdk-bundle-1.11.1026.jar && \
    curl -LO https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/1.4.3/iceberg-spark-runtime-3.5_2.12-1.4.3.jar

# Set environment variable for Spark shell
ENV HOME=/root

# Set Spark Shell as default command with Iceberg + JDBC + S3 configs
ENTRYPOINT ["/opt/spark/bin/spark-sql",\
  "--conf", "spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions",\
  "--conf", "spark.sql.catalog.demo=org.apache.iceberg.spark.SparkCatalog",\
  "--conf", "spark.sql.catalog.demo.catalog-impl=org.apache.iceberg.jdbc.JdbcCatalog",\
  "--conf", "spark.sql.catalog.demo.uri=jdbc:postgresql://catalog-db:5432/iceberg",\
  "--conf", "spark.sql.catalog.demo.jdbc.user=iceberg",\
  "--conf", "spark.sql.catalog.demo.jdbc.password=iceberg",\
  "--conf", "spark.sql.catalog.demo.warehouse=s3a://warehouse/",\
  "--conf", "spark.hadoop.fs.s3a.endpoint=http://minio:9000",\
  "--conf", "spark.hadoop.fs.s3a.access.key=admin",\
  "--conf", "spark.hadoop.fs.s3a.secret.key=password",\
  "--conf", "spark.hadoop.fs.s3a.connection.ssl.enabled=false", \
  "--conf", "spark.hadoop.fs.s3a.path.style.access=true",\
  "--conf", "spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"]
